{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "803d2ebf",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd9c57",
   "metadata": {},
   "source": [
    "Devido ao pouco tempo restante, irei utilizar apenas uma Rede Neural densa como modelo teste.  \n",
    "**Outros modelos que testaria com mais tempo**:\n",
    "- XGBoost\n",
    "- SVM\n",
    "- PCA + KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e53b28",
   "metadata": {},
   "source": [
    "**Motivação**: Automatizar ou criar um sistema de sugestão para a classificação da ocorrência"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efbd26c",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050bd6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83caa81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.neural_network import DenseNeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30a1d0",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d2883e",
   "metadata": {},
   "source": [
    "# Carregando DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76992529",
   "metadata": {},
   "source": [
    "Para esse problema iremos utilizar o \"Cenipa1\", que é o DataSet que considera apenas ocorrência, ocorrência_tipo e aeronave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7838c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DataSets/ML/cenipa1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b05fa5d",
   "metadata": {},
   "source": [
    "# Definindo X e y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29ea18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df.drop(columns=['ocorrencia_classificacao']))\n",
    "y = df['ocorrencia_classificacao'].replace({'INCIDENTE':0,\n",
    "                                           'INCIDENTE GRAVE':1,\n",
    "                                           'ACIDENTE':2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8c2e1b",
   "metadata": {},
   "source": [
    "# Treinando Rede"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ebb3c",
   "metadata": {},
   "source": [
    "## K-fold Crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80882d9c",
   "metadata": {},
   "source": [
    "Vamos utilizar um 5-fold crossvalidation para validar nossos testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "838f0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5df451",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(5, shuffle=True, random_state=42) # Random state mantido em 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7e910b",
   "metadata": {},
   "source": [
    "## Hiper-parâmetros de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3789b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc16c199",
   "metadata": {},
   "source": [
    "## Treinamento em si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3e8e21f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "68/68 [==============================] - 1s 2ms/step - loss: 12.1190 - accuracy: 0.5125\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 5.9021 - accuracy: 0.5210\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 2.8489 - accuracy: 0.5365\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 2.7623 - accuracy: 0.5386\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 1.5343 - accuracy: 0.6078\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 1.4905 - accuracy: 0.6233\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 1.4545 - accuracy: 0.6126\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 1.4912 - accuracy: 0.6099\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8860 - accuracy: 0.6751\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.7757 - accuracy: 0.7352\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.7727\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.7930\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.7902\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.7898\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.8046\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.8215\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8291\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.8284\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5898 - accuracy: 0.7983\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.8030\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.8284\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.8349\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8333\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.8589\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.8474\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8758\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8626\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8659\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8862\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8663\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8545\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3477 - accuracy: 0.8749\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8827\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8851\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8848\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8647\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8841\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8897\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8948\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8950\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8816\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8885\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8936\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8962\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8992\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8908\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8959\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3044 - accuracy: 0.8978\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8952\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.9073\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 23.7380 - accuracy: 0.4882\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9668 - accuracy: 0.5481\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9509 - accuracy: 0.5698\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9450 - accuracy: 0.5779\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9406 - accuracy: 0.5784\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9297 - accuracy: 0.5886\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9218 - accuracy: 0.5920\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9145 - accuracy: 0.5944\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9061 - accuracy: 0.5983\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8902 - accuracy: 0.6055\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8991 - accuracy: 0.6018\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8690 - accuracy: 0.6099\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8673 - accuracy: 0.6117\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8668 - accuracy: 0.6105\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8478 - accuracy: 0.6198\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8411 - accuracy: 0.6327\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.7257 - accuracy: 0.7107\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.6039 - accuracy: 0.7720\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5682 - accuracy: 0.7842\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.7690\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.8187\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.8321\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.8062\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.8208\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8541\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.8231\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8400\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8474\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8356\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8647\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8670\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8712\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8636\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8670\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8499\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8534\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8679\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8562\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8818\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8488\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.8705\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8763\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8700\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8747\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8744\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8740\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8714\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8809\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8543\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8753\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 46.3697 - accuracy: 0.5035\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 1.4126 - accuracy: 0.5835\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9713 - accuracy: 0.6288\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9458 - accuracy: 0.6323\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9072 - accuracy: 0.6665\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8032 - accuracy: 0.6977\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.7612 - accuracy: 0.7172\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.7109 - accuracy: 0.7667\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.7650\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.6048 - accuracy: 0.7990\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.8016\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.8108\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.8101\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8335\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8254\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8432\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8515\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8494\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9558 - accuracy: 0.7870\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 1.3441 - accuracy: 0.7861\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.8411\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8534\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8478\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8578\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8661\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8679\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8677\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8705\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8802\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8737\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8714\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8874\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8832\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.8566\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3599 - accuracy: 0.8728\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8703\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3119 - accuracy: 0.8904\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8848\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8994\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8864\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8945\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8809\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8955\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8973\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8876\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8975\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8932\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.9019\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8874\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8927\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 35.0439 - accuracy: 0.4995\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 1.5173 - accuracy: 0.5446\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8858 - accuracy: 0.6290\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8477 - accuracy: 0.6395\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8415 - accuracy: 0.6279\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8329 - accuracy: 0.6429\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8205 - accuracy: 0.6390\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8060 - accuracy: 0.6529\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.7822 - accuracy: 0.6790\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.7632\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.7636\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9955 - accuracy: 0.6131\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9001 - accuracy: 0.6082\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8936 - accuracy: 0.6115\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.9004 - accuracy: 0.6064\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8898 - accuracy: 0.6133\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8882 - accuracy: 0.6124\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8852 - accuracy: 0.6138\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8681 - accuracy: 0.6242\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.7424\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7986\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7909\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8198\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8235\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8379\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8131\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8393\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8467\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8501\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4064 - accuracy: 0.8448\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8418\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8536\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8721\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8326\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8767\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8823\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8744\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8645\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8679\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3571 - accuracy: 0.8703\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8649\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8890\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8675\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8804\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8869\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3966 - accuracy: 0.8545\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8758\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8726\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8723\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8841\n",
      "Epoch 1/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 31.3661 - accuracy: 0.4921\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 1.4062 - accuracy: 0.5516\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 1.0797 - accuracy: 0.6080\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8535 - accuracy: 0.6057\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8387 - accuracy: 0.6138\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.8120 - accuracy: 0.6376\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.7869 - accuracy: 0.6589\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.7914 - accuracy: 0.6591\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.7037 - accuracy: 0.7248\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7875\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7845\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7981\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8080\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8194\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8249\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.8309\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8460\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8335\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8501\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.7302 - accuracy: 0.7523\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8201\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8536\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.8404\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8265\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8594\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8659\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8645\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8622\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8476\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8733\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8640\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8682\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8698\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8710\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8814\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8749\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8825\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8587\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8786\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8864\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8747\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8728\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8647\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8816\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8476\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8874\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8795\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8855\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8682\n"
     ]
    }
   ],
   "source": [
    "gt=[] # Ground truth total\n",
    "total_pred=[] # Todas as predições do modelo ficarão aqui\n",
    "\n",
    "for train_idxs, test_idxs in kfold.split(df):\n",
    "    \n",
    "    # Separando treino-teste\n",
    "    X_train = X.iloc[train_idxs] \n",
    "    X_test = X.iloc[test_idxs]\n",
    "    y_train = y.iloc[train_idxs]\n",
    "    y_test = y.iloc[test_idxs]\n",
    "    \n",
    "    # Instanciando rede\n",
    "    nn = DenseNeuralNetwork(input_shape=(X.shape[1],),\n",
    "                           n_classes=3)\n",
    "    nn.compile() # Vamos usar os parâmetros default de compilação que colocamos na classe\n",
    "    nn.fit(X_train=X_train, y_train=y_train, batch_size=BATCH_SIZE, epochs=EPOCHS) # .fit\n",
    "\n",
    "    pred = nn.predict(X_test=X_test) # Predict do teste\n",
    "    \n",
    "    # Juntando conteúdo do fold\n",
    "    gt.extend(y_test) \n",
    "    total_pred.extend(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968a6924",
   "metadata": {},
   "source": [
    "# Resultados\n",
    "Vamos verificar os resultados utilizando os métodos prontos do sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd85d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55a482a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      2855\n",
      "           1       0.57      0.38      0.45       761\n",
      "           2       0.90      0.93      0.91      1789\n",
      "\n",
      "    accuracy                           0.86      5405\n",
      "   macro avg       0.78      0.75      0.76      5405\n",
      "weighted avg       0.84      0.86      0.85      5405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gt,total_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d42ebf85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(gt,total_pred), annot=True, robust=True, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776ebe85",
   "metadata": {},
   "source": [
    "# Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8360c0f4",
   "metadata": {},
   "source": [
    "Considero os resultados obtidos como decentes dado o pouco tempo que passei optimizando a rede. O problema pode ser resolvido com métricas ainda melhores dado tempo o suficiente.  \n",
    "\n",
    "**Observações**:\n",
    "- O desbalanceamento das classes afetou negativamente predições de \"INCIDENTE GRAVE\" (focal loss pode ser alternativa)\n",
    "- A rede pode ser retreinada com mais épocas junto à aplicação de Dropout para reduzir viés do treino (possível overfit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
